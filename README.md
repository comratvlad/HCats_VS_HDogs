Hipster Dogs vs. Hipster Cats
=====================
Подготовить выборку из популярных фотографий котов и собак с сайта stocksy.com: поиск осуществлять по тегам cat и dog, объем - по 1000 экземпляров на каждый из двух классов в качестве обучающей выборки и по 400 экземпляров на каждый класс в качестве валидационной выборки. Выбрать и обучить модель классификатора, дающую accuracy на валидационной выборке не ниже 0.8. Предоставить код по сбору данных и по обучению модели (можно на github). Предложить варианты по повышению точности работы классификатора. 

![CatsVSDogs](http://dogsecrets.ru/wp-content/uploads/2001/06/koshki-protiv-sobak.jpg)

Рекомендуемый к использованию язык программирования: python.

## 1. Сбор данных

Источником данных является фотобанк стоковых изображений stocksy.com, не предоставляющий публичного API для своего сайта. Однако производить выборку фотографий всё-таки можно, отправив следующий запрос: "https://www.stocksy.com/search/query?format=json"
с параметрами:

* filters - параметры поиска (теги, формат изображений и т.д.);
* sort - способ сортировки (по популярности, дате добавления...);
* page - номер страницы.

Например: https://www.stocksy.com/search/query?format=json&filters={"text":"cat","orientation":"Horizontal"}&sort=popular&page=1 будет соответствовать первой странице результатов поиска горизонтально ориентированных фотографий по запросу "cat", сортированных по популярности.

Ответ приходит в формате JSON и имеет следующую структуру:
```javascript
{
  "request": {
    "filters": {
      "text": <тег запроса>,
      "orientation": <формат фотографии>,
      "searchAccess": <...>
    },
    "page": <номер страницы>,
    "pageSize": <количество фотографий на странице>,
    "sort": <способ сортировки>
  },
  "response": {
    "returnedItemCount": <количество фотографий на странице>,
    "totalItemCount": <количество фотографий по запросу>,
    "totalPageCount": <количество страниц по запросу>,
    "items": [
      {
        "id": <...>,
        "jpgOriginalWidth": <...>,
        "jpgOriginalHeight": <...>,
        "userString": <...>,
        "userHandle": <...>,
        "title": <...>,
        "type": <...>,
        "orientation": "Horizontal",
        "thumbUrl": <url фотографии (в малом формате)>,
        "dimensions": {
          "pixelwidth": <ширина фотографии в малом формате>,
          "pixelheight": <высота фотографии в малом формате>
        },
        "author": {
          <информация об авторе>
        },
        "variations": {
          "jpgComp": {
            "url": <url фотографии (в большем формате)>,
            "dimensions": {
               "pixelwidth": <ширина фотографии в большем формате>,
               "pixelheight": <высота фотографии в большем формате>
            }
          },
          "jpgFixedWidthDouble": {
            <аналогично предыдущему>
            }
          },
          "jpgFixedWidthLarge": {
            <аналогично предыдущему>
            }
          }
        }
      },
      ...
   }]
   ...
}
```

По ключам "response" -> "items" можно получить информацию о результатах поиска по выбранным параметрам (тег, способ сортировки, номер страницы и т.д.).

Сбор - [hp_loader.py](https://github.com/comratvlad/HCats_vs_HDogs/blob/master/hp_loader.py).
Обработка - [hipster_pets.py](https://github.com/comratvlad/HCats_vs_HDogs/blob/master/hipster_pets.py).

## 2. Подход первый - CNN "в лоб".
Сверточные нейронные сети, при наличии обширной обучающей выборки, очень хорошо справляются с задачей классификации изображений. В нашем случае выборка мала, однако результат обучения неглубокой сети можно будет считать хорошим бейзлайном.

Accuracy после 40 эпох составляет 0.65 - не очень хороший результат.

Код - [first_try.py](https://github.com/comratvlad/HCats_vs_HDogs/blob/master/first_try.py).

## 3. Подход второй - CNN на очищенных данных (+аугментация).
Необходимо почистить обучающую выборку от изображений, не содержащих котов и собак (или содержащих их обоих вместе/таких, где питомца почти не видно) и добавить аугментацию (случайный поворот, сдвиг и т.д. на каждый сэмпл) - это должно привести к значительному улучшению качества.

Accuracy после 60 эпох составляет 0.77 - такой результат близок к желаемому. Более хорошей метрики качества можно было бы добиться более агрессивным Dropout, большим числом эпох, подбору лучшей конфигурации сети. Но на это нет времени, поэтому нужно попробовать другой метод.

Код - [second_try.py](https://github.com/comratvlad/HCats_vs_HDogs/blob/master/second_try.py).

## 4. Подход третий - перенос обучения (transfer learning).
Сейчас одним из самых популярных подходов к практическому обучению глубоких нейронных сетей является перенос обучения (по-английски transfer learning). В этом случае берется предварительно обученная сеть, например, VGG16, Inception или ResNet, и дообучается на наших данных. При таком подходе данных для обучения нужно гораздо меньше, т.к. сеть уже обучена выделять нужные нам признаки, например, на наборе данных ImageNet. Времени для дообучения, как правило, тоже требуется меньше, по сравнению с обучением с нуля.

Возьмем за базовую модель сеть Xception. Согласно документации, это самая продвинутая модель из тех, что предоставляет Keras. 

Теперь accuracy составляет 0.85, что является желаемым результатом. 

Код - [transfer_learning.py](https://github.com/comratvlad/HCats_vs_HDogs/blob/master/transfer_learning.py).

## Выводы
Результаты по трем моделям можно видеть ниже.

Модель                    |             Данные             | Accuracy  |Время обучения |Число эпох
--------------------------|--------------------------------|-----------|---------------|---------------
simple_cnn                | Исходная выборка               |  0.65     | ~100 s/epoch  |40
simple_cnn                | Очищенная выборка, аугментация |  0.77     | ~120 s/epoch  |60
Xception (дообученная)    | Очищенная выборка, аугментация |  0.85     | ~300 s/epoch  |5

Очевидно, данная задача лучше всего решается дообучением уже существующих моделей. В качестве способов улучшения качества можно указать следующее:
* Дообучать большее число слоев существующей сети.
* Использовать более сложную и жесткую аугментацию.
* Использовать регуляризацию при обучении.
* Использовать адаптивный learning rate при обучении - например, контролировать его вручную на каждой эпохе, основываясь на динамике метрики качества.

